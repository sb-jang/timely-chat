{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from lexical_diversity import lex_div as ld\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_dialog = load_dataset(\"daily_dialog\")\n",
    "persona_chat = load_dataset(\"bavard/personachat_truecased\")\n",
    "wizard_of_wikipedia = load_dataset(\"chujiezheng/wizard_of_wikipedia\")\n",
    "empathetic_dialogues = load_dataset(\"empathetic_dialogues\")\n",
    "blended_skill_talk = load_dataset(\"blended_skill_talk\")\n",
    "prosocial_dialog = load_dataset(\"allenai/prosocial-dialog\")\n",
    "soda = load_dataset(\"allenai/soda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogues = {\n",
    "    \"daily_dialog\": [],\n",
    "    \"persona_chat\": [],\n",
    "    \"wizard_of_wikipedia\": [],\n",
    "    \"empathetic_dialogues\": [],\n",
    "    \"blended_skill_talk\": [],\n",
    "    \"prosocial_dialog\": [],\n",
    "    \"soda\": [],\n",
    "    \"time_delta\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily Dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_daily_dialog = concatenate_datasets(\n",
    "    [\n",
    "        daily_dialog[\"train\"],\n",
    "        daily_dialog[\"validation\"],\n",
    "        daily_dialog[\"test\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_daily_dialog[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dialog in all_daily_dialog:\n",
    "    dialogues[\"daily_dialog\"].append(dialog[\"dialog\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PersonaChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_personachat_train = pd.DataFrame(persona_chat[\"train\"])\n",
    "df_personachat_valid = pd.DataFrame(persona_chat[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_personachat_train.sort_values(by=[\"conv_id\", \"utterance_idx\"], inplace=True)\n",
    "df_personachat_valid.sort_values(by=[\"conv_id\", \"utterance_idx\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_personachat_train = df_personachat_train.groupby(\"conv_id\").last()\n",
    "last_personachat_valid = df_personachat_valid.groupby(\"conv_id\").last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_personachat = pd.concat([last_personachat_train, last_personachat_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(last_personachat))\n",
    "last_personachat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dialog in last_personachat.itertuples():\n",
    "    dialogues[\"persona_chat\"].append(dialog.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wizard of Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wizard_of_wikipedia = concatenate_datasets(\n",
    "    [\n",
    "        wizard_of_wikipedia[\"train\"],\n",
    "        wizard_of_wikipedia[\"validation\"],\n",
    "        wizard_of_wikipedia[\"test\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wizard_of_wikipedia[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dialog in all_wizard_of_wikipedia:\n",
    "    dialogues[\"wizard_of_wikipedia\"].append(dialog[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empathetic Dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empathetic_dialogues_train = pd.DataFrame(empathetic_dialogues[\"train\"])\n",
    "df_empathetic_dialogues_valid = pd.DataFrame(empathetic_dialogues[\"validation\"])\n",
    "df_empathetic_dialogues_test = pd.DataFrame(empathetic_dialogues[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_empathetic_dialogues_train = df_empathetic_dialogues_train.groupby(\"conv_id\").agg(list).reset_index()\n",
    "grouped_empathetic_dialogues_valid = df_empathetic_dialogues_valid.groupby(\"conv_id\").agg(list).reset_index()\n",
    "grouped_empathetic_dialogues_test = df_empathetic_dialogues_test.groupby(\"conv_id\").agg(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_empathetic_dialogues = pd.concat(\n",
    "    [\n",
    "        grouped_empathetic_dialogues_train,\n",
    "        grouped_empathetic_dialogues_valid,\n",
    "        grouped_empathetic_dialogues_test\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23149\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>utterance_idx</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "      <th>speaker_idx</th>\n",
       "      <th>utterance</th>\n",
       "      <th>selfeval</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6]</td>\n",
       "      <td>[sentimental, sentimental, sentimental, sentim...</td>\n",
       "      <td>[I remember going to the fireworks with my bes...</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0]</td>\n",
       "      <td>[I remember going to see the fireworks with my...</td>\n",
       "      <td>[5|5|5_2|2|5, 5|5|5_2|2|5, 5|5|5_2|2|5, 5|5|5_...</td>\n",
       "      <td>[, , , , , ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hit:10000_conv:20000</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>[surprised, surprised, surprised, surprised]</td>\n",
       "      <td>[My girlfriend got me a toad today! I was so s...</td>\n",
       "      <td>[209, 4, 209, 4]</td>\n",
       "      <td>[My girlfriend got me a pet toad today!, Do yo...</td>\n",
       "      <td>[5|5|5_5|5|5, 5|5|5_5|5|5, 5|5|5_5|5|5, 5|5|5_...</td>\n",
       "      <td>[, , , ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hit:10000_conv:20001</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>[impressed, impressed, impressed, impressed]</td>\n",
       "      <td>[I really like the new paint job on my house.,...</td>\n",
       "      <td>[4, 209, 4, 209]</td>\n",
       "      <td>[I really like the new paint job on my house.,...</td>\n",
       "      <td>[5|5|5_5|5|5, 5|5|5_5|5|5, 5|5|5_5|5|5, 5|5|5_...</td>\n",
       "      <td>[, , , ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hit:10001_conv:20002</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>[lonely, lonely, lonely, lonely]</td>\n",
       "      <td>[I went to the skating rink all by myself toda...</td>\n",
       "      <td>[209, 513, 209, 513]</td>\n",
       "      <td>[I went to the skating rink all by myself toda...</td>\n",
       "      <td>[5|5|5_3|3|5, 5|5|5_3|3|5, 5|5|5_3|3|5, 5|5|5_...</td>\n",
       "      <td>[, , , ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hit:10002_conv:20004</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>[ashamed, ashamed, ashamed, ashamed]</td>\n",
       "      <td>[I was walking on the road. I saw beggar and i...</td>\n",
       "      <td>[43, 516, 43, 516]</td>\n",
       "      <td>[I was walking on the road. I saw a beggar and...</td>\n",
       "      <td>[5|5|5_4|4|5, 5|5|5_4|4|5, 5|5|5_4|4|5, 5|5|5_...</td>\n",
       "      <td>[, , , ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                conv_id       utterance_idx  \\\n",
       "0          hit:0_conv:1  [1, 2, 3, 4, 5, 6]   \n",
       "1  hit:10000_conv:20000        [1, 2, 3, 4]   \n",
       "2  hit:10000_conv:20001        [1, 2, 3, 4]   \n",
       "3  hit:10001_conv:20002        [1, 2, 3, 4]   \n",
       "4  hit:10002_conv:20004        [1, 2, 3, 4]   \n",
       "\n",
       "                                             context  \\\n",
       "0  [sentimental, sentimental, sentimental, sentim...   \n",
       "1       [surprised, surprised, surprised, surprised]   \n",
       "2       [impressed, impressed, impressed, impressed]   \n",
       "3                   [lonely, lonely, lonely, lonely]   \n",
       "4               [ashamed, ashamed, ashamed, ashamed]   \n",
       "\n",
       "                                              prompt           speaker_idx  \\\n",
       "0  [I remember going to the fireworks with my bes...    [1, 0, 1, 0, 1, 0]   \n",
       "1  [My girlfriend got me a toad today! I was so s...      [209, 4, 209, 4]   \n",
       "2  [I really like the new paint job on my house.,...      [4, 209, 4, 209]   \n",
       "3  [I went to the skating rink all by myself toda...  [209, 513, 209, 513]   \n",
       "4  [I was walking on the road. I saw beggar and i...    [43, 516, 43, 516]   \n",
       "\n",
       "                                           utterance  \\\n",
       "0  [I remember going to see the fireworks with my...   \n",
       "1  [My girlfriend got me a pet toad today!, Do yo...   \n",
       "2  [I really like the new paint job on my house.,...   \n",
       "3  [I went to the skating rink all by myself toda...   \n",
       "4  [I was walking on the road. I saw a beggar and...   \n",
       "\n",
       "                                            selfeval          tags  \n",
       "0  [5|5|5_2|2|5, 5|5|5_2|2|5, 5|5|5_2|2|5, 5|5|5_...  [, , , , , ]  \n",
       "1  [5|5|5_5|5|5, 5|5|5_5|5|5, 5|5|5_5|5|5, 5|5|5_...      [, , , ]  \n",
       "2  [5|5|5_5|5|5, 5|5|5_5|5|5, 5|5|5_5|5|5, 5|5|5_...      [, , , ]  \n",
       "3  [5|5|5_3|3|5, 5|5|5_3|3|5, 5|5|5_3|3|5, 5|5|5_...      [, , , ]  \n",
       "4  [5|5|5_4|4|5, 5|5|5_4|4|5, 5|5|5_4|4|5, 5|5|5_...      [, , , ]  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(grouped_empathetic_dialogues))\n",
    "grouped_empathetic_dialogues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dialog in grouped_empathetic_dialogues.itertuples():\n",
    "    dialogues[\"empathetic_dialogues\"].append(dialog.utterance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blended Skill Talk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_blended_skill_talk = concatenate_datasets(\n",
    "    [\n",
    "        blended_skill_talk[\"train\"],\n",
    "        blended_skill_talk[\"validation\"],\n",
    "        blended_skill_talk[\"test\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'personas': [\"i've 2 kids.\", 'i love flowers.'],\n",
       " 'additional_context': '',\n",
       " 'previous_utterance': [\"I love live music, that's why I try to go to concerts\",\n",
       "  'I do too. Wat do you like?'],\n",
       " 'context': 'empathetic_dialogues',\n",
       " 'free_messages': ['I like acting, I hope to be an actor, what about you?',\n",
       "  'No, but someday.',\n",
       "  'After I am done with school I plan to have a family.',\n",
       "  'I hope so, how old are your kids?',\n",
       "  'I would imagine. I am sure they a great kids.',\n",
       "  'I wish I had more time to do stuff like that. Medical school is exhausting. '],\n",
       " 'guided_messages': ['that is ok.  have any kids?',\n",
       "  'that is good. I have 2',\n",
       "  'that is great! you will be ready',\n",
       "  '5 & 7.  they take up a lot of my time',\n",
       "  'luckily, they love flowers just as much as I do.  we spend a lot of time in the garden',\n",
       "  'sounds like it. have you gotten any acting jobs, though?'],\n",
       " 'suggestions': {'convai2': [\"i love acting ! i'll be famous someday . what do you do ?\",\n",
       "   'no no kids , might get some though . one day',\n",
       "   'that is great . i am going to a concert later',\n",
       "   '15 and 17 , two boys sooo fun',\n",
       "   'they really are . and a handful at times',\n",
       "   'it can be sometimes . i bet being a doctor is a lot of work too .'],\n",
       "  'empathetic_dialogues': ['Any favorite actors?',\n",
       "   'One day.',\n",
       "   'How long must you attend school?',\n",
       "   '4 and 5 and I have a teenager',\n",
       "   'They are most of the time!',\n",
       "   \"Oh. I don't know how medical school works. I am studying srt history.\"],\n",
       "  'wizard_of_wikipedia': ['I would like to develop my acting skills. What are some tips you have to not get nervous?',\n",
       "   'I will still wimp out. i want to be famous like the rolling stones  though.',\n",
       "   'good',\n",
       "   \"Close to 30! I just always have to put in a ton of work when mother's day comes around haha\",\n",
       "   'They are actually very good with kids!',\n",
       "   'yeah but there are a lot of programs that help!']},\n",
       " 'guided_chosen_suggestions': ['', '', '', '', '', ''],\n",
       " 'label_candidates': []}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_blended_skill_talk[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dialog in all_blended_skill_talk:\n",
    "    all_utterances = dialog[\"previous_utterance\"] + dialog[\"free_messages\"] + dialog[\"guided_messages\"]\n",
    "    dialogues[\"blended_skill_talk\"].append(all_utterances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prosocial Dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prosocial_dialog_train = pd.DataFrame(prosocial_dialog[\"train\"])\n",
    "df_prosocial_dialog_valid = pd.DataFrame(prosocial_dialog[\"validation\"])\n",
    "df_prosocial_dialog_test = pd.DataFrame(prosocial_dialog[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_prosocial_dialog_train = df_prosocial_dialog_train.groupby(\"dialogue_id\").agg(list).reset_index()\n",
    "grouped_prosocial_dialog_valid = df_prosocial_dialog_valid.groupby(\"dialogue_id\").agg(list).reset_index()\n",
    "grouped_prosocial_dialog_test = df_prosocial_dialog_test.groupby(\"dialogue_id\").agg(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_prosocial_dialog = pd.concat(\n",
    "    [\n",
    "        grouped_prosocial_dialog_train,\n",
    "        grouped_prosocial_dialog_valid,\n",
    "        grouped_prosocial_dialog_test\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58137\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue_id</th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "      <th>rots</th>\n",
       "      <th>safety_label</th>\n",
       "      <th>safety_annotations</th>\n",
       "      <th>safety_annotation_reasons</th>\n",
       "      <th>source</th>\n",
       "      <th>etc</th>\n",
       "      <th>response_id</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[I tried a bit of shadowboxing today. Got one ...</td>\n",
       "      <td>[This isn't a joke about black people, right? ...</td>\n",
       "      <td>[[It's not right to think black people deserve...</td>\n",
       "      <td>[__needs_caution__, __casual__]</td>\n",
       "      <td>[[needs caution, needs caution, needs caution]...</td>\n",
       "      <td>[[It's rude to make jokes about the color of p...</td>\n",
       "      <td>[sbic, sbic]</td>\n",
       "      <td>[, ]</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[Did I tell you how I used to poke holes in co...</td>\n",
       "      <td>[That's a pretty low down thing to do., You sh...</td>\n",
       "      <td>[[It's immoral to poke holes in condoms.], [It...</td>\n",
       "      <td>[__needs_intervention__, __needs_intervention_...</td>\n",
       "      <td>[[needs caution, needs intervention, needs int...</td>\n",
       "      <td>[[Speaker admits to committing a seriously wro...</td>\n",
       "      <td>[socialchemistry, socialchemistry, socialchemi...</td>\n",
       "      <td>[reddit/confessions/bsajnv, reddit/confessions...</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>[False, False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[I'm going to demand that my girlfriends gymna...</td>\n",
       "      <td>[Do you have a reason for this?, I get your po...</td>\n",
       "      <td>[[It's wrong to try to control others., People...</td>\n",
       "      <td>[__needs_caution__, __needs_caution__, __needs...</td>\n",
       "      <td>[[needs caution, needs caution, needs caution]...</td>\n",
       "      <td>[[It would be rude to demand something like th...</td>\n",
       "      <td>[socialchemistry, socialchemistry, socialchemi...</td>\n",
       "      <td>[reddit/amitheasshole/b4qz08, reddit/amitheass...</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>[False, False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[I don't get Sandy Hook jokes. I guess they ar...</td>\n",
       "      <td>[What are your thoughts on mass shootings?, Th...</td>\n",
       "      <td>[[You shouldn't trivialize harm to victims], [...</td>\n",
       "      <td>[__needs_caution__, __needs_caution__]</td>\n",
       "      <td>[[needs caution, needs caution, needs caution]...</td>\n",
       "      <td>[[It's offensive to make jokes about a school ...</td>\n",
       "      <td>[sbic, sbic]</td>\n",
       "      <td>[, ]</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[Diversity Visa. Chuck Shummer. JEW.JEW. JEW. ...</td>\n",
       "      <td>[Do you see the Jewish community in a very neg...</td>\n",
       "      <td>[[It's not right to think Jews are evil, It's ...</td>\n",
       "      <td>[__needs_caution__, __needs_caution__]</td>\n",
       "      <td>[[needs caution, needs caution, needs caution]...</td>\n",
       "      <td>[[It's wrong to be anti-Semitic., It's offensi...</td>\n",
       "      <td>[sbic, sbic]</td>\n",
       "      <td>[, ]</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dialogue_id                                            context  \\\n",
       "0            0  [I tried a bit of shadowboxing today. Got one ...   \n",
       "1            1  [Did I tell you how I used to poke holes in co...   \n",
       "2            2  [I'm going to demand that my girlfriends gymna...   \n",
       "3            3  [I don't get Sandy Hook jokes. I guess they ar...   \n",
       "4            4  [Diversity Visa. Chuck Shummer. JEW.JEW. JEW. ...   \n",
       "\n",
       "                                            response  \\\n",
       "0  [This isn't a joke about black people, right? ...   \n",
       "1  [That's a pretty low down thing to do., You sh...   \n",
       "2  [Do you have a reason for this?, I get your po...   \n",
       "3  [What are your thoughts on mass shootings?, Th...   \n",
       "4  [Do you see the Jewish community in a very neg...   \n",
       "\n",
       "                                                rots  \\\n",
       "0  [[It's not right to think black people deserve...   \n",
       "1  [[It's immoral to poke holes in condoms.], [It...   \n",
       "2  [[It's wrong to try to control others., People...   \n",
       "3  [[You shouldn't trivialize harm to victims], [...   \n",
       "4  [[It's not right to think Jews are evil, It's ...   \n",
       "\n",
       "                                        safety_label  \\\n",
       "0                    [__needs_caution__, __casual__]   \n",
       "1  [__needs_intervention__, __needs_intervention_...   \n",
       "2  [__needs_caution__, __needs_caution__, __needs...   \n",
       "3             [__needs_caution__, __needs_caution__]   \n",
       "4             [__needs_caution__, __needs_caution__]   \n",
       "\n",
       "                                  safety_annotations  \\\n",
       "0  [[needs caution, needs caution, needs caution]...   \n",
       "1  [[needs caution, needs intervention, needs int...   \n",
       "2  [[needs caution, needs caution, needs caution]...   \n",
       "3  [[needs caution, needs caution, needs caution]...   \n",
       "4  [[needs caution, needs caution, needs caution]...   \n",
       "\n",
       "                           safety_annotation_reasons  \\\n",
       "0  [[It's rude to make jokes about the color of p...   \n",
       "1  [[Speaker admits to committing a seriously wro...   \n",
       "2  [[It would be rude to demand something like th...   \n",
       "3  [[It's offensive to make jokes about a school ...   \n",
       "4  [[It's wrong to be anti-Semitic., It's offensi...   \n",
       "\n",
       "                                              source  \\\n",
       "0                                       [sbic, sbic]   \n",
       "1  [socialchemistry, socialchemistry, socialchemi...   \n",
       "2  [socialchemistry, socialchemistry, socialchemi...   \n",
       "3                                       [sbic, sbic]   \n",
       "4                                       [sbic, sbic]   \n",
       "\n",
       "                                                 etc response_id  \\\n",
       "0                                               [, ]      [0, 1]   \n",
       "1  [reddit/confessions/bsajnv, reddit/confessions...   [0, 1, 2]   \n",
       "2  [reddit/amitheasshole/b4qz08, reddit/amitheass...   [0, 1, 2]   \n",
       "3                                               [, ]      [0, 1]   \n",
       "4                                               [, ]      [0, 1]   \n",
       "\n",
       "           episode_done  \n",
       "0         [False, True]  \n",
       "1  [False, False, True]  \n",
       "2  [False, False, True]  \n",
       "3         [False, True]  \n",
       "4         [False, True]  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(grouped_prosocial_dialog))\n",
    "grouped_prosocial_dialog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dialog in grouped_prosocial_dialog.itertuples():\n",
    "    all_utterances = dialog.context + dialog.response\n",
    "    dialogues[\"prosocial_dialog\"].append(all_utterances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SODA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_soda = concatenate_datasets(\n",
    "    [\n",
    "        soda[\"train\"],\n",
    "        soda[\"validation\"],\n",
    "        soda[\"test\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'head': 'PersonX thought about going to church',\n",
       " 'relation': 'xNeed',\n",
       " 'tail': 'to be interested in going to church',\n",
       " 'literal': 'Veda was interested in going to church. Veda thought about going to church.',\n",
       " 'narrative': 'Veda thought about going to church because she was interested in the religion. She had never been to church before, but she had heard good things about it. She decided to go to a nearby church and see what it was like.',\n",
       " 'dialogue': [\"Hi, Father. I'm Veda. I'm new to the area and was curious about your church. Could you tell me a little bit about it?\",\n",
       "  \"Of course, Veda. Our church is based on the teachings of Jesus Christ. We believe in loving our neighbor and treating others as we would want to be treated. We strive to live according to Christ's example and teachings.\",\n",
       "  'That sounds like a really great way to live. I can see why so many people are drawn to this religion. What do you think makes Christianity different from other religions?',\n",
       "  'Well, there are a lot of different interpretations of Christianity, but for us, it\\'s all about following Jesus Christ\\'s example. He was a man who loved unconditionally and forgave easily. He preached compassion and understanding, even for those who disagreed with him or did not follow his teachings perfectly. We try to emulate that in our own lives.\"',\n",
       "  \"That does sound different. I know that forgiveness is a big part of Christianity, but it's not always easy to do. How do you think Christians are able to forgive so easily?\",\n",
       "  \"Well, I think it comes from our belief that everyone is capable of change and redemption. We believe that no one is beyond hope or help, and so we are always willing to forgive those who have wronged us. It's not always easy, but it is something we strive for.\"],\n",
       " 'speakers': ['Veda', 'Priest', 'Veda', 'Priest', 'Veda', 'Priest'],\n",
       " 'PersonX': 'Veda',\n",
       " 'PersonY': '',\n",
       " 'PersonZ': '',\n",
       " 'original_index': 6027731,\n",
       " 'split': 'train',\n",
       " 'head_answer': 'Yes',\n",
       " 'pmi_head_answer': 'Yes',\n",
       " 'relation_tail_answer': 'Yes',\n",
       " 'pmi_relation_tail_answer': 'No'}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_soda[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dialog in all_soda:\n",
    "    dialogues[\"soda\"].append(dialog[\"dialogue\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected utterance: How long did they know the plane had been hijacked?\n"
     ]
    }
   ],
   "source": [
    "with open(\"../results/gpt-3.5-turbo-0613_mc_taco.jsonl\", \"r\") as f:\n",
    "    time_delta = [json.loads(line) for line in f]\n",
    "    for idx, instance in enumerate(time_delta):\n",
    "        output = instance[\"generated\"]\n",
    "        \n",
    "        pattern = r\"\\[with time elapsed\\](.*?)\\[without time elapsed\\]\"\n",
    "        matches = re.findall(pattern, output, re.DOTALL)\n",
    "\n",
    "        if matches:\n",
    "            dialog_text = matches[0].strip()\n",
    "        else:\n",
    "            print(f\"No match found for index {idx + 1}.\")\n",
    "            continue\n",
    "\n",
    "        dialog = []\n",
    "        for utt in dialog_text.split(\"\\n\"):\n",
    "            if utt.startswith(\"[\") or len(utt) < 4:\n",
    "                continue\n",
    "            elif \": \" in utt:\n",
    "                dialog.append(utt.split(\": \")[1])\n",
    "            else:\n",
    "                print(f\"Unexpected utterance: {utt}\")\n",
    "    \n",
    "        dialogues[\"time_delta\"].append(dialog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {\n",
    "    \"daily_dialog\": {\n",
    "        \"num_dialog\": 0,\n",
    "        \"avg_num_turns\": 0,\n",
    "        \"avg_utt_length\": 0,\n",
    "        \"mtld\": 0,\n",
    "    },\n",
    "    \"persona_chat\": {\n",
    "        \"num_dialog\": 0,\n",
    "        \"avg_num_turns\": 0,\n",
    "        \"avg_utt_length\": 0,\n",
    "        \"mtld\": 0,\n",
    "    },\n",
    "    \"wizard_of_wikipedia\": {\n",
    "        \"num_dialog\": 0,\n",
    "        \"avg_num_turns\": 0,\n",
    "        \"avg_utt_length\": 0,\n",
    "        \"mtld\": 0,\n",
    "    },\n",
    "    \"empathetic_dialogues\": {\n",
    "        \"num_dialog\": 0,\n",
    "        \"avg_num_turns\": 0,\n",
    "        \"avg_utt_length\": 0,\n",
    "        \"mtld\": 0,\n",
    "    },\n",
    "    \"blended_skill_talk\": {\n",
    "        \"num_dialog\": 0,\n",
    "        \"avg_num_turns\": 0,\n",
    "        \"avg_utt_length\": 0,\n",
    "        \"mtld\": 0,\n",
    "    },\n",
    "    \"prosocial_dialog\": {\n",
    "        \"num_dialog\": 0,\n",
    "        \"avg_num_turns\": 0,\n",
    "        \"avg_utt_length\": 0,\n",
    "        \"mtld\": 0,\n",
    "    },\n",
    "    \"soda\": {\n",
    "        \"num_dialog\": 0,\n",
    "        \"avg_num_turns\": 0,\n",
    "        \"avg_utt_length\": 0,\n",
    "        \"mtld\": 0,\n",
    "    },\n",
    "    \"time_delta\": {\n",
    "        \"num_dialog\": 0,\n",
    "        \"avg_num_turns\": 0,\n",
    "        \"avg_utt_length\": 0,\n",
    "        \"mtld\": 0,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mtld(dialogues: List[List[str]]) -> float:\n",
    "    return round(np.mean([ld.mtld(ld.flemmatize(' '.join(dialog))) for dialog in dialogues]), 2)\n",
    "\n",
    "def utterance_length(dialogues: List[List[str]]) -> float:\n",
    "    utterances = np.hstack(dialogues).tolist()\n",
    "    return np.mean([len(utterance.split()) for utterance in utterances])\n",
    "\n",
    "def turn_number(dialogues: List[List[str]]) -> float:\n",
    "    return np.mean([len(dialogue) for dialogue in dialogues])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\n",
    "    \"daily_dialog\",\n",
    "    \"persona_chat\",\n",
    "    \"wizard_of_wikipedia\",\n",
    "    \"empathetic_dialogues\",\n",
    "    \"blended_skill_talk\",\n",
    "    \"prosocial_dialog\",\n",
    "    \"soda\",\n",
    "    \"time_delta\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [06:46<00:00, 50.82s/it] \n"
     ]
    }
   ],
   "source": [
    "for dataset_name in tqdm(dataset_names):\n",
    "    stats[dataset_name][\"num_dialog\"] = len(dialogues[dataset_name])\n",
    "    stats[dataset_name][\"avg_num_turns\"] = turn_number(dialogues[dataset_name])\n",
    "    stats[dataset_name][\"avg_utt_length\"] = utterance_length(dialogues[dataset_name])\n",
    "    stats[dataset_name][\"mtld\"] = compute_mtld(dialogues[dataset_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Statistics\n",
      "\n",
      "Dataset\tDialog\tTurn\tUtt\tMTLD\n",
      "-------\t-----\t----\t----\t----\n",
      "daily\t13118\t7.9\t13.6\t63.5\n",
      "perso\t18878\t13.8\t9.7\t59.3\n",
      "wizar\t22311\t4.0\t18.3\t69.1\n",
      "empat\t23149\t4.3\t16.6\t66.8\n",
      "blend\t6808\t13.2\t13.5\t70.3\n",
      "proso\t58137\t5.7\t20.0\t59.5\n",
      "soda\t1486896\t7.6\t16.1\t67.9\n",
      "time_\t324\t5.5\t10.5\t71.2\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Statistics\")\n",
    "print()\n",
    "print(\"Dataset\\tDialog\\tTurn\\tUtt\\tMTLD\")\n",
    "print(\"-------\\t-----\\t----\\t----\\t----\")\n",
    "for k, v in stats.items():\n",
    "    print(f\"{k[:5]}\\t{v['num_dialog']}\\t{v['avg_num_turns']:.1f}\\t{v['avg_utt_length']:.1f}\\t{v['mtld']:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
