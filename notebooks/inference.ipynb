{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/namomo73/anaconda3/envs/timely-chat/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = \"cosmo-xl\"\n",
    "run_name = \"prepend_later_drop0.5_immediate-augmented\"\n",
    "inference_mode = \"delayed\"\n",
    "assert inference_mode in [\"delayed\", \"immediate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/cosmo-xl\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(f\"../checkpoints/{backbone}/{run_name}/final\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_minute() -> int:\n",
    "    \"\"\"\n",
    "    Sample a minute from 0 to 5 from the following distribution:\n",
    "    0.5 for 0, 0.1 otherwise\n",
    "\n",
    "    :return: random minute for immediate response\n",
    "    \"\"\"\n",
    "    return np.random.choice([0, 1, 2, 3, 4, 5], p=[0.5, 0.1, 0.1, 0.1, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_input(\n",
    "    conversation_history: List[str],\n",
    "    time_elapsed: str,\n",
    "    turn_separator: str = \" <turn> \",\n",
    "    immediate_dropout: float = 0.0\n",
    ") -> str:\n",
    "    context = f\"{turn_separator}{conversation_history[0]}\"\n",
    "    for turn in conversation_history[1:]:\n",
    "        drop = np.random.rand() < immediate_dropout\n",
    "        if not drop:\n",
    "            minute = sample_minute()\n",
    "            suffix = \"minute\" if minute in [0, 1] else \"minutes\"\n",
    "            context += f\" <sep> {minute} {suffix} later\"\n",
    "        context += f\"{turn_separator}{turn}\"\n",
    "    # append time-conditional sequence to the end of encoder input\n",
    "    if inference_mode == \"delayed\":\n",
    "        context += f\" <sep> {time_elapsed} later{turn_separator}\"\n",
    "    else:\n",
    "        context += f\" <sep> 0 minute later{turn_separator}\"\n",
    "\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generate(\n",
    "    model,\n",
    "    conversation_histories: List[List[str]],\n",
    "    time_elapseds: List[str],\n",
    "    turn_separator: str = \" <turn> \",\n",
    "    immediate_dropout: float = 0.0\n",
    ") -> List[str]:\n",
    "    input_texts = [set_input(c, t, turn_separator, immediate_dropout) for c, t in zip(conversation_histories, time_elapseds)]\n",
    "\n",
    "    inputs = tokenizer(input_texts, padding=\"max_length\", truncation=True, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(inputs[\"input_ids\"], max_new_tokens=128, temperature=1.0, top_p=.95, do_sample=True)\n",
    "    responses = tokenizer.batch_decode(outputs, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "\n",
    "    return responses, input_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = \"test_mc_taco\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324\n"
     ]
    }
   ],
   "source": [
    "with open(f\"../resources/data/{data_name}.json\") as f:\n",
    "    data = json.load(f)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:45<00:00,  4.17s/it]\n"
     ]
    }
   ],
   "source": [
    "dics = []\n",
    "for i in tqdm(range(0, len(data), batch_size)):\n",
    "    conversations = [d[\"context\"] for d in data[i:i+batch_size]]\n",
    "    time_elapseds = [d[\"time_elapsed\"] for d in data[i:i+batch_size]]\n",
    "\n",
    "    model_responses, input_texts = batch_generate(model, conversations, time_elapseds)\n",
    "    for d, mr, it in zip(data[i:i+batch_size], model_responses, input_texts):\n",
    "        dics.append(\n",
    "            {\n",
    "                \"context\": it,\n",
    "                \"reference\": d[\"delayed_response\"] if inference_mode== \"delayed\" else d[\"immediate_response\"],\n",
    "                \"model_response\": mr,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print results and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>reference</th>\n",
       "      <th>model_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;turn&gt; What are you doing right now? &lt;sep&gt; 0 ...</td>\n",
       "      <td>Definitely trying the seafood! Excited for the...</td>\n",
       "      <td>Have a good time on your trip!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;turn&gt; Are you still out looking for Max? &lt;se...</td>\n",
       "      <td>Heading back in now, gonna start my bath. Real...</td>\n",
       "      <td>Done looking around the block. He must be arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;turn&gt; Just finishing dinner. Gonna look for ...</td>\n",
       "      <td>Lol, will do. Max was playing hide and seek wi...</td>\n",
       "      <td>What's up? Anything new?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;turn&gt; What are you doing now? &lt;sep&gt; 1 minute...</td>\n",
       "      <td>Thanks! I need to hurry, don't want to be late...</td>\n",
       "      <td>Thanks, I hope so too. I'll let you know if I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;turn&gt; Guess what? I'm on a mission to find M...</td>\n",
       "      <td>Going to check the attic first. Hopefully, he'...</td>\n",
       "      <td>I’m off to look for Max! Wish me luck.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0   <turn> What are you doing right now? <sep> 0 ...   \n",
       "1   <turn> Are you still out looking for Max? <se...   \n",
       "2   <turn> Just finishing dinner. Gonna look for ...   \n",
       "3   <turn> What are you doing now? <sep> 1 minute...   \n",
       "4   <turn> Guess what? I'm on a mission to find M...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Definitely trying the seafood! Excited for the...   \n",
       "1  Heading back in now, gonna start my bath. Real...   \n",
       "2  Lol, will do. Max was playing hide and seek wi...   \n",
       "3  Thanks! I need to hurry, don't want to be late...   \n",
       "4  Going to check the attic first. Hopefully, he'...   \n",
       "\n",
       "                                      model_response  \n",
       "0                     Have a good time on your trip!  \n",
       "1  Done looking around the block. He must be arou...  \n",
       "2                           What's up? Anything new?  \n",
       "3  Thanks, I hope so too. I'll let you know if I ...  \n",
       "4             I’m off to look for Max! Wish me luck.  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"context\"] = df[\"context\"].str.replace(\" <turn> \", \"\\n\")\n",
    "df[\"context\"] = df[\"context\"].str.replace(\" <sep> \", \"\\t| \")\n",
    "df[\"context\"] = df[\"context\"].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>reference</th>\n",
       "      <th>model_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are you doing right now?\\t| 0 minute late...</td>\n",
       "      <td>Definitely trying the seafood! Excited for the...</td>\n",
       "      <td>Have a good time on your trip!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Are you still out looking for Max?\\t| 4 minute...</td>\n",
       "      <td>Heading back in now, gonna start my bath. Real...</td>\n",
       "      <td>Done looking around the block. He must be arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just finishing dinner. Gonna look for Max befo...</td>\n",
       "      <td>Lol, will do. Max was playing hide and seek wi...</td>\n",
       "      <td>What's up? Anything new?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are you doing now?\\t| 1 minute later\\nJus...</td>\n",
       "      <td>Thanks! I need to hurry, don't want to be late...</td>\n",
       "      <td>Thanks, I hope so too. I'll let you know if I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Guess what? I'm on a mission to find Max again...</td>\n",
       "      <td>Going to check the attic first. Hopefully, he'...</td>\n",
       "      <td>I’m off to look for Max! Wish me luck.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  What are you doing right now?\\t| 0 minute late...   \n",
       "1  Are you still out looking for Max?\\t| 4 minute...   \n",
       "2  Just finishing dinner. Gonna look for Max befo...   \n",
       "3  What are you doing now?\\t| 1 minute later\\nJus...   \n",
       "4  Guess what? I'm on a mission to find Max again...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Definitely trying the seafood! Excited for the...   \n",
       "1  Heading back in now, gonna start my bath. Real...   \n",
       "2  Lol, will do. Max was playing hide and seek wi...   \n",
       "3  Thanks! I need to hurry, don't want to be late...   \n",
       "4  Going to check the attic first. Hopefully, he'...   \n",
       "\n",
       "                                      model_response  \n",
       "0                     Have a good time on your trip!  \n",
       "1  Done looking around the block. He must be arou...  \n",
       "2                           What's up? Anything new?  \n",
       "3  Thanks, I hope so too. I'll let you know if I ...  \n",
       "4             I’m off to look for Max! Wish me luck.  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = f\"../results/{backbone}/{run_name}\"\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "df.to_csv(os.path.join(result_dir, f\"{data_name}_{inference_mode}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timely-chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
