{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/namomo73/anaconda3/envs/timely-chat/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = \"cosmo-xl\"\n",
    "run_name = \"prepend_later_drop0.5\"\n",
    "inference_mode = \"delayed\"\n",
    "assert inference_mode in [\"delayed\", \"immediate\"]\n",
    "test_set = \"test_mc_taco\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"../results/{backbone}/{run_name}/{test_set}_{inference_mode}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>reference</th>\n",
       "      <th>model_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are you doing right now?\\t| 0 minute late...</td>\n",
       "      <td>You were right about the seafood, absolutely a...</td>\n",
       "      <td>Now the ports! Where are you headed next?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Are you still out looking for Max?\\t| 0 minute...</td>\n",
       "      <td>Just got in the bath. No luck finding Max, but...</td>\n",
       "      <td>Okay, I'm heading in now.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just finishing dinner. Gonna look for Max befo...</td>\n",
       "      <td>Found Max hiding in the laundry room! Heading ...</td>\n",
       "      <td>Max's in the tub now!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are you doing now?\\t| 0 minute later\\nJus...</td>\n",
       "      <td>Found him napping in the laundry room. Bath ti...</td>\n",
       "      <td>I finally found Max! He was hiding behind the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Guess what? I'm on a mission to find Max again...</td>\n",
       "      <td>Found Max! He was in the attic all along.</td>\n",
       "      <td>Okay, let’s see...he’s hiding under the couch!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  What are you doing right now?\\t| 0 minute late...   \n",
       "1  Are you still out looking for Max?\\t| 0 minute...   \n",
       "2  Just finishing dinner. Gonna look for Max befo...   \n",
       "3  What are you doing now?\\t| 0 minute later\\nJus...   \n",
       "4  Guess what? I'm on a mission to find Max again...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  You were right about the seafood, absolutely a...   \n",
       "1  Just got in the bath. No luck finding Max, but...   \n",
       "2  Found Max hiding in the laundry room! Heading ...   \n",
       "3  Found him napping in the laundry room. Bath ti...   \n",
       "4          Found Max! He was in the attic all along.   \n",
       "\n",
       "                                      model_response  \n",
       "0          Now the ports! Where are you headed next?  \n",
       "1                          Okay, I'm heading in now.  \n",
       "2                              Max's in the tub now!  \n",
       "3  I finally found Max! He was hiding behind the ...  \n",
       "4     Okay, let’s see...he’s hiding under the couch!  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SacreBLEU, ROUGE, METEOR, Distinct-n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs_for_bleu = df[\"reference\"].apply(lambda x: [str(x).lower()]).tolist()\n",
    "refs = df[\"reference\"].apply(lambda x: str(x).lower()).tolist()\n",
    "hyps = df[\"model_response\"].apply(lambda x: str(x).lower()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/namomo73/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/namomo73/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/namomo73/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "bleu = load(\"sacrebleu\")\n",
    "rouge = load(\"rouge\")\n",
    "meteor = load(\"meteor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct(seqs: List[str]):\n",
    "    \"\"\"Calculate intra/inter distinct 1/2.\"\"\"\n",
    "    batch_size = len(seqs)\n",
    "    intra_dist1, intra_dist2 = [], []\n",
    "    unigrams_all, bigrams_all = Counter(), Counter()\n",
    "    for seq in seqs:\n",
    "        tokenized = seq.split()\n",
    "        unigrams = Counter(tokenized)\n",
    "        bigrams = Counter(zip(tokenized, tokenized[1:]))\n",
    "        intra_dist1.append((len(unigrams)+1e-12) / (len(tokenized)+1e-5))\n",
    "        intra_dist2.append((len(bigrams)+1e-12) / (max(0, len(tokenized)-1)+1e-5))\n",
    "\n",
    "        unigrams_all.update(unigrams)\n",
    "        bigrams_all.update(bigrams)\n",
    "\n",
    "    # inter: average of all sequences\n",
    "    inter_dist1 = (len(unigrams_all)+1e-12) / (sum(unigrams_all.values())+1e-5)\n",
    "    inter_dist2 = (len(bigrams_all)+1e-12) / (sum(bigrams_all.values())+1e-5)\n",
    "    # intra: average over average of each sequence\n",
    "    intra_dist1 = np.average(intra_dist1)\n",
    "    intra_dist2 = np.average(intra_dist2)\n",
    "    return inter_dist1, inter_dist2, intra_dist1, intra_dist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_score = bleu.compute(predictions=hyps, references=refs_for_bleu, lowercase=True)\n",
    "rouge_score = rouge.compute(predictions=hyps, references=refs, rouge_types=[\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
    "meteor_score = meteor.compute(predictions=hyps, references=refs)\n",
    "distinct1, distinct2, _, _ = distinct(hyps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: cosmo-xl\n",
      "setup: prepend_later_drop0.5\n",
      "mode: delayed\n",
      "test set: test_mc_taco\n",
      "====================\n",
      "BLEU: 2.36\n",
      "ROUGE-1: 15.06\n",
      "ROUGE-2: 3.24\n",
      "ROUGE-L: 12.78\n",
      "METEOR: 13.73\n",
      "Distinct-1: 29.27\n",
      "Distinct-2: 74.11\n"
     ]
    }
   ],
   "source": [
    "print(f\"model: {backbone}\\nsetup: {run_name}\\nmode: {inference_mode}\\ntest set: {test_set}\")\n",
    "print(\"=\" * 20)\n",
    "print(f\"BLEU: {bleu_score['score']:.2f}\")\n",
    "print(f\"ROUGE-1: {rouge_score['rouge1'] * 100:.2f}\")\n",
    "print(f\"ROUGE-2: {rouge_score['rouge2'] * 100:.2f}\")\n",
    "print(f\"ROUGE-L: {rouge_score['rougeL'] * 100:.2f}\")\n",
    "print(f\"METEOR: {meteor_score['meteor'] * 100:.2f}\")\n",
    "print(f\"Distinct-1: {distinct1 * 100:.2f}\")\n",
    "print(f\"Distinct-2: {distinct2 * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timely-chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
